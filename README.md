## 第一步：

首先我们打开你的GitHub账号主页，
![image-20240419161256552](https://github.com/Alycho/aqcDataMining/assets/154504214/cbcb333d-8f06-4360-addf-0d304fc97c77)






在账号首页右上角找到一个加号，点击里面有一个New repository选项即创建新的仓库，进行选择。

点击之后，我们来到下图这个界面。

![image-20240419161534560](https://github.com/Alycho/aqcDataMining/assets/154504214/11278f42-f1ad-418e-bae5-6adfb0d40365)


接下来，我们一个空一个空进行说明

# 第二步：

## 一、Repository name

这里输入框即输入你仓库的名字，你可以想一个适当的名字进行填写。

## 二、Descriptioin（optional）

根据名字我们可知其意，就是对你创建仓库的描述，当然，这个可以选填。

## 三、Public、Private

Public即为公众的，选了Public即代表你的仓库代码为公开的，仓库内的所有内容都会被公开。

Private即为私有的，选了Private即代表你的仓库为私密的，当然你选了这个也可以自己设置访问权限。相比Public多了一些功能，那它肯定是收费的，哈哈哈。如果只是自己的练习或者不重要的信息，当然我们没必要去选择付费的这一项。

## 四、Initialize this repository with a README

如果勾选了这个选项，那么它就代表着GitHub会自动初始化仓库并且设置README文件，可以让你立刻clone这个仓库。clone意思就是本地没有repository（仓库）时，将远程repository（仓库）整个下载过来。如果不勾选它，那么，你可以手动push。将你已经有的Git仓库添加到GitHub。

## 五、Add .gitignore

在使用git作版本控制时，git会默认把git控制的文件夹里面的所有文件都加入到版本控制。但是在实践中，我们经常会遇到不想某些文件或文件夹被git追踪的情况。比如logs文件、代码构建过程中产生的一些列文件，要解决这种问题,通常情况下我们需要创建一个文件格式后缀名为.gitignore的文件，来控制那些文件不被git追踪。

这里所说的git追踪，通俗一点来讲就是在我们push上传文件的时候，这些文件不会被上传。只会存在你本地的磁盘里，不会随你要上传的文件一起上传，它会被滤过。

下拉菜单中有多种语言及框架，看你的需要进行选择。

## 六、Add a license

这个下拉菜单意思是给你的代码仓库添加一个许可证，你可以根据需求进行选择。比如我添加一个开源许可证，当别人浏览我的代码仓库时，别人也可以进行修改我仓库中的项目。

随后会生成包含许可协议内容的LICENSE文件，用力啊表明你的仓库内容的许可协议。

完成以上六个步骤，点击Create repository按钮，即完成仓库的创建！

当我们来到下面这个界面时，说明你的仓库已经创建好了

该页面的网址即为你仓库的页面

![image-20240419161644901](https://github.com/Alycho/aqcDataMining/assets/154504214/0f3f485a-081b-4069-916e-c3a258c7d180)


我们创建好之后，这是你可以看到一个README.md的文件，这个文件中是你的仓库的概要、使用流程、许可协议等信息。

https://github.com/Alycho/aqcDataMining/

OK啦，GitHub创建自己的仓库就已经完成了。

# 第三步：

## 最想学习的深度学习中的技能：

我的研究方向属于CV中的图像融合，隶属于图像增强中的一中。我的细分方向为红外可见图像融合，我的方向在最近几年深受深度学习的影响，尤其是pytorch框架已经是主流的研究框架。所以在这个背景下，我想学习关于pytorch的各种技能。例如如何去搭建VGG-16网络。VGG-16是一种深度卷积神经网络，由牛津大学的研究团队开发，被用于图像分类和对象识别任务。VGG-16的名称来源于其网络结构：它由16个卷积层和3个全连接层组成。下面是VGG-16的基本结构：

1. 输入层：接受输入图像。
2. 卷积层：由13个卷积层组成，每个卷积层后面都跟着一个ReLU激活函数，用于提取图像特征。
3. 池化层：在卷积层之间插入5个最大池化层，用于降低特征图的维度和计算量。
4. 全连接层：由3个全连接层组成，用于将提取的特征映射到输出类别。

VGG-16的结构相对简单，但由于其深度和参数数量的增加，使得它在图像分类任务中表现出色。然而，由于VGG-16的参数数量较大，因此在训练和推理过程中需要更多的计算资源和时间。

对于vgg网络的兴趣来源于我所阅读的论文当中，作为一个非常成熟，方便插入且训练完成的网络，它的出现频率相当之高，所以我产生了想要学习搭建它的想法。

![image-20240419163043584](https://github.com/Alycho/aqcDataMining/assets/154504214/669fbbfe-ad7e-471f-8342-9e480aab110b)

以上是我在学习后完成的网络搭建。

交叉注意力：由于多模态视觉信息融合的目标是将多传感器的信息融合到一幅包含更多互补信息和更少冗余特征的图像中。然而，互补信息很难提取，特别是对于红外和可见光图像，这两种模式之间存在很大的相似性差距。常见的交叉注意模块只考虑图像的相关性，而图像融合任务则需要关注图像的互补性（不相关性）。所以我在transfomer的基础上找到了这个变体 交叉注意力
![1713862715962](https://github.com/Alycho/aqcDataMining/assets/154504214/7d8e49b8-c7ab-4dfb-9b89-57838bd8818d)

交叉注意力CAM最核心的地方在于矩阵相乘之后的激活函数如图所示。

再接下来我在我的研究方向所了解到了 一种基于记忆单元的通用无监督图像融合网络   具体来说，在本单元中，我们利用训练过程中获得的中间融合结果来进一步协作监督融合图像。这样，我们的融合结果不仅可以从原始输入图像中学习，还可以受益于网络本身的中间输出。

- 存储器单元：![eb4701b8-2d45-4705-a0fc-22dbf6a3fcbb-26585901](https://github.com/Alycho/aqcDataMining/assets/154504214/7b222e24-8338-4874-9fbf-fd96f88026e7)

  如图所示，在传统的无监督图像融合方法中，训练过程中获得的中间结果被简单地丢弃。然而，这些中间结果包含了融合任务的重要线索：像素强度分布、结构相似性和梯度信息，可以提供丰富的监督信号来指导训练过程。因此，为了进一步提高这些无监督方法的性能，设计了一个存储单元来收集前一个时期的输出，并计算两个自适应比率来监督网络训练的过程。
- 损失函数：![1492d59b-4380-4882-9ca9-44d985fde803-26585901](https://github.com/Alycho/aqcDataMining/assets/154504214/481b8e5a-7399-4966-9daa-9e62b56a30b5)
  如图所示，我们的损失函数旨在保留源图像的显着部分以生成信息丰富的融合输出，因此在内容损失项中采用显着区域掩模。另一方面，我们期望这个无监督训练过程能够从之前的输出中学习，因此，我们进一步设计了基于记忆单元的记忆损失项。用 𝑝1 和 𝑝2 来平衡保存程度，我们的损失函数定义为： 𝐿total = 𝑝1 ⋅ 𝐿content + 𝑝2 ⋅ 𝐿memory，
- 网络架构图：![6da4d9e4-74ac-4330-8536-791587bc3845-26585901](https://github.com/Alycho/aqcDataMining/assets/154504214/e4aea426-c861-40f8-bfe2-103c59e8363c)
  所提出的 MUFusion 的网络架构。源图像首先在通道维度上串联。接下来，它们被输入到密集提取块中，以提取具有两个尺度的显着特征。通过这种方式，这些具有两个尺度的提取块有望分别传达详细的外观和语义信息。之后，这些图像特征由两个重建块重建以获得融合输出。此外，在密集提取块和重建块中分别引入密集连接和跳跃连接，以平滑地聚合图像特征。具体来说，对于提取块，前几层的输出特征被连接在一起作为当前卷积层的输入。相反，重建块中的卷积层还接收相应编码器层的输出特征作为输入。卷积层中的“A”和“B”（“A×B”）表示输入和输出通道的数量。所有涉及的卷积运算都使用标准的 3 × 3 内核。下采样过程是利用步长为2的卷积运算实现的。


